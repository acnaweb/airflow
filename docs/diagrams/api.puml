@startuml data-ingestion-api

title Diagrama de Sequência: Pipeline de Dados com Cloud Scheduler, Cloud Function/Run, Dataflow/PySpark, BigQuery e Looker

' ====== Estilo opcional ======
hide footbox
skinparam ParticipantPadding 20
skinparam BoxPadding 15
skinparam ActorStyle awesome
skinparam BackgroundColor #FFFFFF
skinparam Sequence {
    ArrowThickness 1
    LifeLineBorderColor #777777
    LifeLineBackgroundColor #DDDDDD
    ParticipantBorderColor #004D99
    ParticipantBackgroundColor #EDF4FF
    ActorBorderColor #004D99
    ActorBackgroundColor #CDE3FF
}

actor "Cloud Scheduler / Composer" as Scheduler
participant "Cloud Function\nou Cloud Run\n(Orquestrador)" as Orchestrator
participant "API Externa" as ExternalAPI
database "Cloud Storage\n(TB)" as GCS_TB
participant "Dataflow / PySpark\n(Transformação)" as TransformJob
database "BigQuery\nTR" as BQ_TR
participant "Dataform\n(opcional)" as Dataform
database "BigQuery\nRF" as BQ_RF
actor "Looker / BI" as Looker

== Ingestão bruta (TB) ==
Scheduler -> Orchestrator : ⚡ Trigger agendado
Orchestrator -> ExternalAPI : GET /dados (com autenticação)
ExternalAPI --> Orchestrator : JSON/CSV/XML payload
Orchestrator -> GCS_TB : Salva dados brutos (Parquet/JSON)

== Transformação (TR) ==
Orchestrator -> TransformJob : Trigger transformação
TransformJob -> GCS_TB : Lê dados brutos
TransformJob -> BQ_TR : Escreve dados limpos/enriquecidos

== Modelagem semântica (RF) ==
note over Dataform : execução via agendamento Composer/Scheduler
Dataform -> BQ_TR : SELECT transform SQL
Dataform -> BQ_RF : Cria tabelas finais RF

== Consumo analítico ==
Looker -> BQ_RF : query dashboards
@enduml
